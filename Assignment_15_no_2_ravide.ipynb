{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assigment_15_no. 2_ravide.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oqVEmBACRMil"
      },
      "source": [
        "# Jawaban No. 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDv1_W8-P3fv"
      },
      "source": [
        "## Persiapan Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qK3sViy_oGet"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import vgg16\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from tensorflow.keras.optimizers import SGD, Adam, Adamax"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38zMnJhtoTr0"
      },
      "source": [
        "# fungsi ploting loss history\n",
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ftp7PNf0oVif"
      },
      "source": [
        "# mengekstrak data dari file zip ke colab\n",
        "zip_path = '/content/drive/My\\ Drive/abc/cats-dogs.zip'\n",
        "\n",
        "!cp {zip_path} /content/\n",
        "\n",
        "!cd /content/\n",
        "\n",
        "!unzip -q /content/cats-dogs.zip -d /content\n",
        "\n",
        "!rm /content/cats-dogs.zip"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Exxlx09cok39"
      },
      "source": [
        "# membagi data train dan validation\n",
        "dasar_dir = '/content/'\n",
        "training_dir = os.path.join(dasar_dir, 'train')\n",
        "validation_dir = os.path.join(dasar_dir, 'test')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmWuqSMqomec"
      },
      "source": [
        "# menentukan hyperparameter image augmentation\n",
        "datagen = ImageDataGenerator(rescale=1./255, \n",
        "                            shear_range=0.2, \n",
        "                            rotation_range=20, \n",
        "                            horizontal_flip=True, \n",
        "                            fill_mode='nearest')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npfNeNUWoojs",
        "outputId": "c5768ea1-f67d-410d-fb02-fccb676f37a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# melakukan image augmentation pada data train dan validation\n",
        "train_iterator = datagen.flow_from_directory(training_dir,\n",
        "                                             class_mode='binary', \n",
        "                                             batch_size=128,\n",
        "                                             target_size=(200, 200))\n",
        "\n",
        "val_iterator = datagen.flow_from_directory(validation_dir,\n",
        "                                           class_mode='binary',\n",
        "                                           batch_size=128,\n",
        "                                           target_size=(200, 200))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 12749 images belonging to 2 classes.\n",
            "Found 2252 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DTUz3RTYoqql",
        "outputId": "7f0e49ec-dc5f-4a24-ead0-5e92dbffd60e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# membuat arsitektur model\n",
        "vgg_conv = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(200, 200, 3))\n",
        "\n",
        "for layer in vgg_conv.layers[:]:\n",
        "  layer.trainable = False\n",
        "\n",
        "ft_model = Sequential()\n",
        "\n",
        "ft_model.add(vgg_conv)\n",
        "ft_model.add(BatchNormalization(axis=1))\n",
        "ft_model.add(Dropout(0.25))\n",
        "\n",
        "ft_model.add(Flatten())\n",
        "ft_model.add(Dense(512, activation='relu', kernel_initializer='he_uniform'))\n",
        "ft_model.add(Dropout(0.5))\n",
        "ft_model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "opt = Adam(lr=0.0001)\n",
        "\n",
        "ft_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='accuracy', patience=10, mode='max')\n",
        "\n",
        "cnn_model.summary()\n",
        "\n",
        "history = ft_model.fit(train_iterator,\n",
        "                        steps_per_epoch=len(train_iterator),\n",
        "                        callbacks=[callback],\n",
        "                        validation_data=val_iterator, \n",
        "                        validation_steps=len(val_iterator),\n",
        "                        epochs=20)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_6 (Conv2D)            (None, 198, 198, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 99, 99, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 97, 97, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 46, 46, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 23, 23, 128)       0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 67712)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 128)               8667264   \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 8,760,641\n",
            "Trainable params: 8,760,641\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/20\n",
            "100/100 [==============================] - 147s 1s/step - loss: 0.4113 - accuracy: 0.8194 - val_loss: 0.2984 - val_accuracy: 0.8686\n",
            "Epoch 2/20\n",
            "100/100 [==============================] - 146s 1s/step - loss: 0.2707 - accuracy: 0.8838 - val_loss: 0.2189 - val_accuracy: 0.9116\n",
            "Epoch 3/20\n",
            "100/100 [==============================] - 146s 1s/step - loss: 0.2467 - accuracy: 0.8957 - val_loss: 0.2189 - val_accuracy: 0.9085\n",
            "Epoch 4/20\n",
            "100/100 [==============================] - 146s 1s/step - loss: 0.2379 - accuracy: 0.8965 - val_loss: 0.1995 - val_accuracy: 0.9196\n",
            "Epoch 5/20\n",
            "100/100 [==============================] - 146s 1s/step - loss: 0.2166 - accuracy: 0.9095 - val_loss: 0.2020 - val_accuracy: 0.9165\n",
            "Epoch 6/20\n",
            "100/100 [==============================] - 146s 1s/step - loss: 0.2071 - accuracy: 0.9132 - val_loss: 0.1860 - val_accuracy: 0.9258\n",
            "Epoch 7/20\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.2046 - accuracy: 0.9138 - val_loss: 0.1864 - val_accuracy: 0.9214\n",
            "Epoch 8/20\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.1943 - accuracy: 0.9187 - val_loss: 0.1831 - val_accuracy: 0.9245\n",
            "Epoch 9/20\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.1985 - accuracy: 0.9165 - val_loss: 0.1758 - val_accuracy: 0.9290\n",
            "Epoch 10/20\n",
            "100/100 [==============================] - 146s 1s/step - loss: 0.1836 - accuracy: 0.9220 - val_loss: 0.1739 - val_accuracy: 0.9276\n",
            "Epoch 11/20\n",
            "100/100 [==============================] - 146s 1s/step - loss: 0.1853 - accuracy: 0.9194 - val_loss: 0.1791 - val_accuracy: 0.9303\n",
            "Epoch 12/20\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.1766 - accuracy: 0.9225 - val_loss: 0.1944 - val_accuracy: 0.9218\n",
            "Epoch 13/20\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.1780 - accuracy: 0.9265 - val_loss: 0.1814 - val_accuracy: 0.9258\n",
            "Epoch 14/20\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.1723 - accuracy: 0.9278 - val_loss: 0.1838 - val_accuracy: 0.9281\n",
            "Epoch 15/20\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.1724 - accuracy: 0.9274 - val_loss: 0.1669 - val_accuracy: 0.9338\n",
            "Epoch 16/20\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.1657 - accuracy: 0.9316 - val_loss: 0.1795 - val_accuracy: 0.9303\n",
            "Epoch 17/20\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.1659 - accuracy: 0.9297 - val_loss: 0.1671 - val_accuracy: 0.9303\n",
            "Epoch 18/20\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.1607 - accuracy: 0.9328 - val_loss: 0.1749 - val_accuracy: 0.9298\n",
            "Epoch 19/20\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.1518 - accuracy: 0.9362 - val_loss: 0.1789 - val_accuracy: 0.9250\n",
            "Epoch 20/20\n",
            "100/100 [==============================] - 145s 1s/step - loss: 0.1513 - accuracy: 0.9374 - val_loss: 0.1652 - val_accuracy: 0.9312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZNLn440BZGq",
        "outputId": "63823341-916f-445d-c9a9-abcd981bdf89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "source": [
        "# membuat datframe dari history\n",
        "df_history = pd.DataFrame(history.history)\n",
        "df_history['epoch'] = history.epoch\n",
        "df_history"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.411282</td>\n",
              "      <td>0.819358</td>\n",
              "      <td>0.298368</td>\n",
              "      <td>0.868561</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.270662</td>\n",
              "      <td>0.883834</td>\n",
              "      <td>0.218851</td>\n",
              "      <td>0.911634</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.246702</td>\n",
              "      <td>0.895678</td>\n",
              "      <td>0.218900</td>\n",
              "      <td>0.908526</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.237915</td>\n",
              "      <td>0.896541</td>\n",
              "      <td>0.199471</td>\n",
              "      <td>0.919627</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.216599</td>\n",
              "      <td>0.909483</td>\n",
              "      <td>0.201977</td>\n",
              "      <td>0.916519</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.207068</td>\n",
              "      <td>0.913170</td>\n",
              "      <td>0.185970</td>\n",
              "      <td>0.925844</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.204578</td>\n",
              "      <td>0.913797</td>\n",
              "      <td>0.186398</td>\n",
              "      <td>0.921403</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.194281</td>\n",
              "      <td>0.918739</td>\n",
              "      <td>0.183070</td>\n",
              "      <td>0.924512</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.198453</td>\n",
              "      <td>0.916464</td>\n",
              "      <td>0.175783</td>\n",
              "      <td>0.928952</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.183623</td>\n",
              "      <td>0.921955</td>\n",
              "      <td>0.173910</td>\n",
              "      <td>0.927620</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.185250</td>\n",
              "      <td>0.919366</td>\n",
              "      <td>0.179146</td>\n",
              "      <td>0.930284</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.176564</td>\n",
              "      <td>0.922504</td>\n",
              "      <td>0.194438</td>\n",
              "      <td>0.921847</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.177992</td>\n",
              "      <td>0.926504</td>\n",
              "      <td>0.181391</td>\n",
              "      <td>0.925844</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.172340</td>\n",
              "      <td>0.927837</td>\n",
              "      <td>0.183752</td>\n",
              "      <td>0.928064</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.172445</td>\n",
              "      <td>0.927445</td>\n",
              "      <td>0.166863</td>\n",
              "      <td>0.933837</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.165733</td>\n",
              "      <td>0.931602</td>\n",
              "      <td>0.179492</td>\n",
              "      <td>0.930284</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.165937</td>\n",
              "      <td>0.929720</td>\n",
              "      <td>0.167086</td>\n",
              "      <td>0.930284</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.160708</td>\n",
              "      <td>0.932779</td>\n",
              "      <td>0.174925</td>\n",
              "      <td>0.929840</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.151787</td>\n",
              "      <td>0.936230</td>\n",
              "      <td>0.178899</td>\n",
              "      <td>0.924956</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.151315</td>\n",
              "      <td>0.937407</td>\n",
              "      <td>0.165209</td>\n",
              "      <td>0.931172</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "0   0.411282  0.819358  0.298368      0.868561      0\n",
              "1   0.270662  0.883834  0.218851      0.911634      1\n",
              "2   0.246702  0.895678  0.218900      0.908526      2\n",
              "3   0.237915  0.896541  0.199471      0.919627      3\n",
              "4   0.216599  0.909483  0.201977      0.916519      4\n",
              "5   0.207068  0.913170  0.185970      0.925844      5\n",
              "6   0.204578  0.913797  0.186398      0.921403      6\n",
              "7   0.194281  0.918739  0.183070      0.924512      7\n",
              "8   0.198453  0.916464  0.175783      0.928952      8\n",
              "9   0.183623  0.921955  0.173910      0.927620      9\n",
              "10  0.185250  0.919366  0.179146      0.930284     10\n",
              "11  0.176564  0.922504  0.194438      0.921847     11\n",
              "12  0.177992  0.926504  0.181391      0.925844     12\n",
              "13  0.172340  0.927837  0.183752      0.928064     13\n",
              "14  0.172445  0.927445  0.166863      0.933837     14\n",
              "15  0.165733  0.931602  0.179492      0.930284     15\n",
              "16  0.165937  0.929720  0.167086      0.930284     16\n",
              "17  0.160708  0.932779  0.174925      0.929840     17\n",
              "18  0.151787  0.936230  0.178899      0.924956     18\n",
              "19  0.151315  0.937407  0.165209      0.931172     19"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZTWrneLBc4z",
        "outputId": "5040a67d-037e-4bfa-9220-55e8fb35c52a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "source": [
        "# melakukan sort niali val_accuracy terbaik\n",
        "df_history.sort_values(by='val_accuracy', ascending=False)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.172445</td>\n",
              "      <td>0.927445</td>\n",
              "      <td>0.166863</td>\n",
              "      <td>0.933837</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.151315</td>\n",
              "      <td>0.937407</td>\n",
              "      <td>0.165209</td>\n",
              "      <td>0.931172</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0.165937</td>\n",
              "      <td>0.929720</td>\n",
              "      <td>0.167086</td>\n",
              "      <td>0.930284</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.165733</td>\n",
              "      <td>0.931602</td>\n",
              "      <td>0.179492</td>\n",
              "      <td>0.930284</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.185250</td>\n",
              "      <td>0.919366</td>\n",
              "      <td>0.179146</td>\n",
              "      <td>0.930284</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.160708</td>\n",
              "      <td>0.932779</td>\n",
              "      <td>0.174925</td>\n",
              "      <td>0.929840</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.198453</td>\n",
              "      <td>0.916464</td>\n",
              "      <td>0.175783</td>\n",
              "      <td>0.928952</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.172340</td>\n",
              "      <td>0.927837</td>\n",
              "      <td>0.183752</td>\n",
              "      <td>0.928064</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.183623</td>\n",
              "      <td>0.921955</td>\n",
              "      <td>0.173910</td>\n",
              "      <td>0.927620</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.207068</td>\n",
              "      <td>0.913170</td>\n",
              "      <td>0.185970</td>\n",
              "      <td>0.925844</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.177992</td>\n",
              "      <td>0.926504</td>\n",
              "      <td>0.181391</td>\n",
              "      <td>0.925844</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.151787</td>\n",
              "      <td>0.936230</td>\n",
              "      <td>0.178899</td>\n",
              "      <td>0.924956</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.194281</td>\n",
              "      <td>0.918739</td>\n",
              "      <td>0.183070</td>\n",
              "      <td>0.924512</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0.176564</td>\n",
              "      <td>0.922504</td>\n",
              "      <td>0.194438</td>\n",
              "      <td>0.921847</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.204578</td>\n",
              "      <td>0.913797</td>\n",
              "      <td>0.186398</td>\n",
              "      <td>0.921403</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.237915</td>\n",
              "      <td>0.896541</td>\n",
              "      <td>0.199471</td>\n",
              "      <td>0.919627</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.216599</td>\n",
              "      <td>0.909483</td>\n",
              "      <td>0.201977</td>\n",
              "      <td>0.916519</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.270662</td>\n",
              "      <td>0.883834</td>\n",
              "      <td>0.218851</td>\n",
              "      <td>0.911634</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.246702</td>\n",
              "      <td>0.895678</td>\n",
              "      <td>0.218900</td>\n",
              "      <td>0.908526</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.411282</td>\n",
              "      <td>0.819358</td>\n",
              "      <td>0.298368</td>\n",
              "      <td>0.868561</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        loss  accuracy  val_loss  val_accuracy  epoch\n",
              "14  0.172445  0.927445  0.166863      0.933837     14\n",
              "19  0.151315  0.937407  0.165209      0.931172     19\n",
              "16  0.165937  0.929720  0.167086      0.930284     16\n",
              "15  0.165733  0.931602  0.179492      0.930284     15\n",
              "10  0.185250  0.919366  0.179146      0.930284     10\n",
              "17  0.160708  0.932779  0.174925      0.929840     17\n",
              "8   0.198453  0.916464  0.175783      0.928952      8\n",
              "13  0.172340  0.927837  0.183752      0.928064     13\n",
              "9   0.183623  0.921955  0.173910      0.927620      9\n",
              "5   0.207068  0.913170  0.185970      0.925844      5\n",
              "12  0.177992  0.926504  0.181391      0.925844     12\n",
              "18  0.151787  0.936230  0.178899      0.924956     18\n",
              "7   0.194281  0.918739  0.183070      0.924512      7\n",
              "11  0.176564  0.922504  0.194438      0.921847     11\n",
              "6   0.204578  0.913797  0.186398      0.921403      6\n",
              "3   0.237915  0.896541  0.199471      0.919627      3\n",
              "4   0.216599  0.909483  0.201977      0.916519      4\n",
              "1   0.270662  0.883834  0.218851      0.911634      1\n",
              "2   0.246702  0.895678  0.218900      0.908526      2\n",
              "0   0.411282  0.819358  0.298368      0.868561      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "foinCbp_ozPl",
        "outputId": "fdd87441-4493-4305-a3c6-bda88c1a3241",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        }
      },
      "source": [
        "# plotting nilai loss antara data train vs validation\n",
        "plot_loss(history)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxOQwRURLwb-"
      },
      "source": [
        "## Kesimpulan:\n",
        "- Perbedaan Tunning hyperparameter sebelumnya (no.1) yaitu pada image augmentasion (melakukan shear dan rotation) yang dilakukan ke data train dan validation kemudian pada model dilakukan Fine-Tunning dengan CGG16 serta melakukan regularization dengan BatchNormalization dan Dropout, dan optimizer yang digunakan yaitu Adam dengan lr=0.0001 dan epochs=20.\n",
        "- Hasil prediksi yang dihasilkan lumayan bagus (good fit) dengan val_accuracy terbaik bernilai 0.93 dan train_accuracy = 0.93 sedangkan val_loss = 0.166 dan train_loss = 0.171 pada epoch = 14, yang berarti accuracy dan loss data train vs validation sudah saling setara dengan masing2 accuracy diatas 90% atau menandakan good fit prediction di epoch = 14."
      ]
    }
  ]
}